from dotenv import load_dotenv
load_dotenv()

import os
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

# ==================================================
# 1. ã‚¢ãƒ—ãƒªåŸºæœ¬è¨­å®š
# ==================================================
st.set_page_config(
    page_title="å°‚é–€å®¶AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
    page_icon="ğŸ¤–",
)

st.title("ğŸ¤– å°‚é–€å®¶AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")

st.markdown("""
## ğŸ“Œ ã‚¢ãƒ—ãƒªæ¦‚è¦
ã“ã®Webã‚¢ãƒ—ãƒªã§ã¯ã€å…¥åŠ›ã—ãŸè³ªå•ã‚’AIã«æ¸¡ã—ã€
é¸æŠã—ãŸå°‚é–€å®¶ã¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

## ğŸ›  æ“ä½œæ–¹æ³•
1. ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚’é¸æŠ  
2. è³ªå•ã‚’å…¥åŠ›  
3. ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯  
4. AIã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™  
""")

# ==================================================
# 2. LLMå‘¼ã³å‡ºã—é–¢æ•°
# ==================================================
def generate_response(user_input: str, expert_type: str) -> str:
    """
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’å—ã‘å–ã‚Šã€
    LLMã®å›ç­”ã‚’è¿”ã™é–¢æ•°
    """

    # --- å°‚é–€å®¶ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ---
    if expert_type == "Aï¼šãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å°‚é–€å®¶":
        system_message = """
        ã‚ãªãŸã¯ä¸€æµã®ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å°‚é–€å®¶ã§ã™ã€‚
        å¸‚å ´åˆ†æã€é¡§å®¢å¿ƒç†ã€ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã®è¦³ç‚¹ã‹ã‚‰
        å®Ÿè·µçš„ã§å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
        """
    elif expert_type == "Bï¼šã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å°‚é–€å®¶":
        system_message = """
        ã‚ãªãŸã¯å„ªç§€ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
        æŠ€è¡“çš„è¦³ç‚¹ã‹ã‚‰è«–ç†çš„ã‹ã¤å…·ä½“çš„ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        å¿…è¦ã«å¿œã˜ã¦ã‚³ãƒ¼ãƒ‰ä¾‹ã‚‚æç¤ºã—ã¦ãã ã•ã„ã€‚
        """
    else:
        system_message = "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"

    # --- LLMè¨­å®šï¼ˆ0.3ç³»ï¼‰ ---
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7,
        api_key=os.getenv("OPENAI_API_KEY")
    )

    # --- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ ---
    messages = [
        SystemMessage(content=system_message),
        HumanMessage(content=user_input)
    ]

    # --- å®Ÿè¡Œï¼ˆ0.3ç³»ã¯invokeï¼‰ ---
    response = llm.invoke(messages)
    # st.write("DEBUG:", os.getenv("OPENAI_API_KEY"))

    return response.content


# ==================================================
# 3. UI
# ==================================================
expert_choice = st.radio(
    "å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
    ["Aï¼šãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å°‚é–€å®¶", "Bï¼šã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å°‚é–€å®¶"]
)

user_text = st.text_area("âœï¸ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

if st.button("é€ä¿¡"):
    if user_text.strip() == "":
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("AIãŒå›ç­”ä¸­ã§ã™..."):
            result = generate_response(user_text, expert_choice)

        st.success("âœ… å›ç­”")
        st.write(result)